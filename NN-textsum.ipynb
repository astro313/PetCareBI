{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Purpose-of-this-notebook:-NN-for-text-summarization-(yelp-review)\" data-toc-modified-id=\"Purpose-of-this-notebook:-NN-for-text-summarization-(yelp-review)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Purpose of this notebook: NN for text summarization (yelp review)</a></span></li><li><span><a href=\"#Before-actual-analysis\" data-toc-modified-id=\"Before-actual-analysis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Before actual analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-as-usual\" data-toc-modified-id=\"Import-as-usual-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import as usual</a></span></li><li><span><a href=\"#load-files\" data-toc-modified-id=\"load-files-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>load files</a></span></li></ul></li><li><span><a href=\"#Google's-T5\" data-toc-modified-id=\"Google's-T5-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Google's T5</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#review-ID-33\" data-toc-modified-id=\"review-ID-33-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>review ID 33</a></span></li><li><span><a href=\"#review-ID-2811\" data-toc-modified-id=\"review-ID-2811-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>review ID 2811</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook: NN for text summarization (yelp review)\n",
    "seq2seq model that can create relevant summaries\n",
    "\n",
    "https://cs224d.stanford.edu/reports/lucilley.pdf for abstractive summary\n",
    "\n",
    "http://kavita-ganesan.com/opinosis-opinion-dataset/#.Xt_Mq2pKjUJ but it's java.\n",
    "\n",
    "or try: https://arxiv.org/pdf/1911.02247.pdf (unsupervised)\n",
    "trained on yelp and amazon reviews, but there's no pre-trained.. -- just got it from the author. \n",
    "\n",
    "CUrrenlty using GOogle's T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before actual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:11:43.926707Z",
     "start_time": "2020-06-09T20:11:43.854497Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Specify renderer\n",
    "# matplotlib.use('Agg')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# Boiler-plate settings for producing pub-quality figures\n",
    "# 1 point = 1/72 inch\n",
    "from cycler import cycler\n",
    "matplotlib.rcParams['axes.prop_cycle'] = cycler(color='bgrcmyk')\n",
    "matplotlib.rcParams.update({\n",
    "    'figure.figsize': (8, 5)  # inches\n",
    "    ,\n",
    "    'font.size':\n",
    "    22  # points\n",
    "    ,\n",
    "    'legend.fontsize':\n",
    "    16  # points\n",
    "    ,\n",
    "    'lines.linewidth':\n",
    "    1.5  # points\n",
    "    ,\n",
    "    'axes.linewidth':\n",
    "    1.5  # points\n",
    "    ,\n",
    "    'text.usetex':\n",
    "    True  # Use LaTeX to layout text\n",
    "    ,\n",
    "    'font.family':\n",
    "    \"serif\"  # Use serifed fonts\n",
    "    ,\n",
    "    'xtick.major.size':\n",
    "    10  # length, points\n",
    "    ,\n",
    "    'xtick.major.width':\n",
    "    1.5  # points\n",
    "    ,\n",
    "    'xtick.minor.size':\n",
    "    6  # length, points\n",
    "    ,\n",
    "    'xtick.minor.width':\n",
    "    1  # points\n",
    "    ,\n",
    "    'ytick.major.size':\n",
    "    10  # length, points\n",
    "    ,\n",
    "    'ytick.major.width':\n",
    "    1.5  # points\n",
    "    ,\n",
    "    'ytick.minor.size':\n",
    "    6  # length, points\n",
    "    ,\n",
    "    \"xtick.minor.visible\":\n",
    "    True,\n",
    "    \"ytick.minor.visible\":\n",
    "    True,\n",
    "    'font.weight':\n",
    "    'bold',\n",
    "    'ytick.minor.width':\n",
    "    1  # points\n",
    "    ,\n",
    "    'font.serif': (\"Times\", \"Palatino\", \"Computer Modern Roman\",\n",
    "                   \"New Century Schoolbook\", \"Bookman\"),\n",
    "    'font.sans-serif':\n",
    "    (\"Helvetica\", \"Avant Garde\", \"Computer Modern Sans serif\"),\n",
    "    'font.monospace': (\"Courier\", \"Computer Modern Typewriter\"),\n",
    "    'font.cursive':\n",
    "    \"Zapf Chancery\"\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:11:44.082280Z",
     "start_time": "2020-06-09T20:11:44.028425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:11:44.350264Z",
     "start_time": "2020-06-09T20:11:44.184703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: free: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:11:45.247683Z",
     "start_time": "2020-06-09T20:11:45.198575Z"
    }
   },
   "outputs": [],
   "source": [
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:11:45.755007Z",
     "start_time": "2020-06-09T20:11:45.701727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# ML\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "#Set the display format to be scientific for ease of analysis\n",
    "# pd.options.display.float_format = '{:,.2g}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:11:50.566329Z",
     "start_time": "2020-06-09T20:11:50.513779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.13.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:11:50.728077Z",
     "start_time": "2020-06-09T20:11:50.678867Z"
    }
   },
   "outputs": [],
   "source": [
    "# NLP\n",
    "import gensim \n",
    "from gensim import models\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora\n",
    "# import tensorflow \n",
    "\n",
    "import re, string \n",
    "import pandas as pd   \n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# libraries for visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:11:52.371491Z",
     "start_time": "2020-06-09T20:11:52.318257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No repo found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import subprocess\n",
    "    gitd = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))\n",
    "    githash = subprocess.check_output('git --git-dir={0:s} --work-tree={1:s} '\\\n",
    "              'rev-parse HEAD'.format(gitd+'/.git',gitd),shell=True).rstrip()\n",
    "except:\n",
    "    githash = 'No repo found'\n",
    "\n",
    "print(githash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:11:55.393803Z",
     "start_time": "2020-06-09T20:11:55.341631Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install transformers==2.8.0\n",
    "# !pip install torch==1.4.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:31:57.443948Z",
     "start_time": "2020-06-09T20:31:56.954537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Tue Jun 09 2020 \n",
      "\n",
      "CPython 3.7.6\n",
      "IPython 7.13.0\n",
      "\n",
      "jupyerlab not installed\n",
      "torch 1.4.0\n",
      "transformers 2.8.0\n",
      "numpy 1.18.1\n",
      "scipy 1.4.1\n",
      "sklearn 0.22.1\n",
      "pandas 1.0.3\n",
      "matplotlib 3.1.3\n",
      "nltk 3.2.5\n",
      "gensim 3.3.0\n",
      "tensorflow 1.13.2\n",
      "spacy 2.2.4\n",
      "\n",
      "compiler   : Clang 4.0.1 (tags/RELEASE_401/final)\n",
      "system     : Darwin\n",
      "release    : 19.5.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "host name  : C02X61QTJHD5\n",
      "Git hash   : 44a47330a83555e2112d050ede552dbc16d91040\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -h -n -g -m -p jupyerlab,torch,transformers,numpy,scipy,sklearn,pandas,matplotlib,nltk,gensim,tensorflow,spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:13:04.664578Z",
     "start_time": "2020-06-09T20:13:04.618770Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:13:17.176828Z",
     "start_time": "2020-06-09T20:13:04.767475Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_yelp_files(region):\n",
    "    region = region.lower()\n",
    "    if region == 'ny':\n",
    "        review_files = glob.glob('scraped_data_nodupl_biz/' + '1????*csv')\n",
    "    elif region == 'sf':\n",
    "        review_files = glob.glob('scraped_data_nodupl_biz/' + '9????*csv')\n",
    "    df_new = load_review_helper.read_all_reviews_in_area(review_files)\n",
    "    df_new.drop_duplicates(inplace=True, keep='first')\n",
    "    return df_new\n",
    "\n",
    "df_NY = load_yelp_files('ny')\n",
    "df_SF = load_yelp_files('sf')\n",
    "df = pd.concat([df_NY, df_SF])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:21:07.149570Z",
     "start_time": "2020-06-09T20:21:07.074471Z"
    }
   },
   "outputs": [],
   "source": [
    "# del df_new\n",
    "# df_new = pd.read_csv('data_model/cleaned_tokenized_df-2020-06-07.csv')\n",
    "# df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google's T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "device = torch.device('cpu')\n",
    "text =\"\"\"\n",
    "The US has \"passed the peak\" on new coronavirus cases, President Donald Trump said and predicted that some states would reopen this month.\n",
    "The US has over 637,000 confirmed Covid-19 cases and over 30,826 deaths, the highest for any country in the world.\n",
    "At the daily White House coronavirus briefing on Wednesday, Trump said new guidelines to reopen the country would be announced on Thursday after he speaks to governors.\n",
    "\"We'll be the comeback kids, all of us,\" he said. \"We want to get our country back.\"\n",
    "The Trump administration has previously fixed May 1 as a possible date to reopen the world's largest economy, but the president said some states may be able to return to normalcy earlier than that.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "print (\"original text preprocessed: \\n\", preprocess_text)\n",
    "\n",
    "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "# summmarize \n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:21:58.839340Z",
     "start_time": "2020-06-09T20:21:53.698468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text preprocessed: \n",
      " Have brought my dog Pixel to Happy Paws for grooming for the last 7 years.She's always well taken care of and the staff is really nice. I buy my pet food from here as well, it's a great one stop shop for dogs and cats.\n",
      "\n",
      "\n",
      "Summarized text: \n",
      " Pixel is a great one stop shop for dogs and cats. she's always well taken care of and the staff is really nice!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "text = df['review_text'].iloc[5]\n",
    "\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "print (\"original text preprocessed: \\n\", preprocess_text)\n",
    "\n",
    "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "# summmarize \n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review ID 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:44:50.373071Z",
     "start_time": "2020-06-09T20:44:47.342007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text preprocessed: \n",
      " STAY AWAY if you need reliability. I paid for a sitter to come after confirming dates and availability. The sitter canceled on me without refunding my payment. I was told to contact the owner and have chased him for over a month now via email, phone, and in person. I have left emails, messages, and have been assured by the secretary that I would be contacted, but nothing has come of it. The \"office\" (actually just his place of residence) is said to be available, but I have been there and nobody responds. I never received my money back, and also wasted my time and energy trying to get my money back. Thankfully I was able to get a more reliable sitter elsewhere on short notice.UPDATE: the owner emailed and refunded me immediately after writing this review. This shows that he was actively ignoring me until I could do something about it. He has tried to bribe me with money to remove this review. Perhaps the reason he has a good rating on yelp is because he is bribing his bad reviewers...\n",
      "\n",
      "\n",
      "Summarized text: \n",
      " a sitter canceled on me without refunding my payment. the owner emailed and refunded me immediately after writing this review - he has tried to bribe me with money to remove this rant if i can do something about it'she is blundering his bad reviewers'\n"
     ]
    }
   ],
   "source": [
    "text = df['review_text'].iloc[33]\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "print (\"original text preprocessed: \\n\", preprocess_text)\n",
    "\n",
    "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "# summmarize \n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=1,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:45:13.217210Z",
     "start_time": "2020-06-09T20:45:05.548108Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text preprocessed: \n",
      " STAY AWAY if you need reliability. I paid for a sitter to come after confirming dates and availability. The sitter canceled on me without refunding my payment. I was told to contact the owner and have chased him for over a month now via email, phone, and in person. I have left emails, messages, and have been assured by the secretary that I would be contacted, but nothing has come of it. The \"office\" (actually just his place of residence) is said to be available, but I have been there and nobody responds. I never received my money back, and also wasted my time and energy trying to get my money back. Thankfully I was able to get a more reliable sitter elsewhere on short notice.UPDATE: the owner emailed and refunded me immediately after writing this review. This shows that he was actively ignoring me until I could do something about it. He has tried to bribe me with money to remove this review. Perhaps the reason he has a good rating on yelp is because he is bribing his bad reviewers...\n",
      "\n",
      "\n",
      "Summarized text: \n",
      " the owner emailed and refunded me immediately after writing this review. he has tried to bribe me with money to remove the review.\n"
     ]
    }
   ],
   "source": [
    "text = df['review_text'].iloc[33]\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "print (\"original text preprocessed: \\n\", preprocess_text)\n",
    "\n",
    "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "# summmarize \n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:45:27.060547Z",
     "start_time": "2020-06-09T20:45:25.302171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text preprocessed: \n",
      " STAY AWAY if you need reliability. I paid for a sitter to come after confirming dates and availability. The sitter canceled on me without refunding my payment. I was told to contact the owner and have chased him for over a month now via email, phone, and in person. I have left emails, messages, and have been assured by the secretary that I would be contacted, but nothing has come of it. The \"office\" (actually just his place of residence) is said to be available, but I have been there and nobody responds. I never received my money back, and also wasted my time and energy trying to get my money back. Thankfully I was able to get a more reliable sitter elsewhere on short notice.UPDATE: the owner emailed and refunded me immediately after writing this review. This shows that he was actively ignoring me until I could do something about it. He has tried to bribe me with money to remove this review. Perhaps the reason he has a good rating on yelp is because he is bribing his bad reviewers...\n",
      "\n",
      "\n",
      "Summarized text: \n",
      " a sitter canceled on me without refunding my payment. the owner emailed and refunded me immediately after writing this review - he has tried to bribe me with money to remove this rant \n"
     ]
    }
   ],
   "source": [
    "text = df['review_text'].iloc[33]\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "print (\"original text preprocessed: \\n\", preprocess_text)\n",
    "\n",
    "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "# summmarize \n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=1,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=50,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:47:09.701359Z",
     "start_time": "2020-06-09T20:47:06.624794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Summarized text: \n",
      " a sitter canceled on me without refunding my payment. the owner emailed and refunded me immediately after writing this review - he has tried to bribe me with money to remove this rant if i can do something about it'she is blundering his bad reviewers'\n"
     ]
    }
   ],
   "source": [
    "# summmarize \n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=1,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=200,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review ID 2811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:47:39.951242Z",
     "start_time": "2020-06-09T20:47:18.919459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text preprocessed: \n",
      " We brought our new adoptee lab mix here over Christmas for a two-night stay on our way up to the Poconos.  We were very excited to find a place with a spot available at this busy time of year on such short notice, which we'd reserved a few days earlier.  And we had a great 15 minute chat with the owner on the phone at the time.  Which is why we were super surprised when we came to drop our boy off and the owner not only insisted that we failed to secure the reservation by not submitting the intake form in advance (which we were never told during that 15 minute phone call was required to secure the reservation), but was rude about it and acted like we were imposing on him by coming on the busiest day of the year without a reservation (which as I said we were sure we had secured).  After a few minutes of him giving my wife an attitude I called him on it, which caught him off guard but quickly prompted an apology.  He disappeared for a few minutes only to return saying that they'd moved a few things around and would be able to accommodate us.  Let me be clear: he made it seem like he was doing us a favor by taking our dog at the last minute on a busy night without us having a reservation.  But in reality, we believed (and had no reason to think otherwise) that we had secured a reservation, so he was not doing us a favor.  Had we known that the reservation was not secured a few days earlier, we might've called around to find another place.  But given that we were dropping out dog off on our way to our vacation destination we had no choice but to leave our dog with this person who we were not at all comfortable with.  When we came back to get him two days later, the dog seemed happy but we got no feedback from the owner when asking about how his stay was.  The handler seemed to be taking an interest in the dogs (including ours), which is why I gave them 2 stars instead of 1.  But be warned, the owner has 'tude (at least he did for us).\n",
      "\n",
      "\n",
      "Summarized text: \n",
      " we brought our adoptee lab mix here over Christmas for a two-night stay on our way up to the Poconos. the owner insisted that we failed to secure the reservation by not submitting the intake form in advance, but was rude about it and acted like we were imposing on him by coming on the busiest day of the year without reservation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = df['review_text'].iloc[2811]\n",
    "\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "print (\"original text preprocessed: \\n\", preprocess_text)\n",
    "\n",
    "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "# summmarize \n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:47:44.008714Z",
     "start_time": "2020-06-09T20:47:40.203203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Summarized text: \n",
      " we brought our adoptee lab mix to the poconos over christmas. the dog was not doing us a favor, so he was unable to secure 'a reservation' despite the fact that we had waited for the reservation - we were not sure if we would have secured it!\n"
     ]
    }
   ],
   "source": [
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=1,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T20:47:48.196654Z",
     "start_time": "2020-06-09T20:47:44.226400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Summarized text: \n",
      " we brought our adoptee lab mix to the poconos over christmas. the dog was not doing us a favor, so he was unable to secure 'a reservation' despite the fact that we had waited for the reservation - we were not sure if we would have secured it!\n"
     ]
    }
   ],
   "source": [
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=1,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=200,\n",
    "                                    early_stopping=True)\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
