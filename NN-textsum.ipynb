{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN for text summarization\n",
    "seq2seq model that can create relevant summaries\n",
    "\n",
    "https://cs224d.stanford.edu/reports/lucilley.pdf for abstractive summary\n",
    "\n",
    "http://kavita-ganesan.com/opinosis-opinion-dataset/#.Xt_Mq2pKjUJ but it's java.\n",
    "\n",
    "or try: https://arxiv.org/pdf/1911.02247.pdf\n",
    "trained on yelp and amazon reviews, but there's no pre-trained.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Specify renderer\n",
    "# matplotlib.use('Agg')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# Boiler-plate settings for producing pub-quality figures\n",
    "# 1 point = 1/72 inch\n",
    "from cycler import cycler\n",
    "matplotlib.rcParams['axes.prop_cycle'] = cycler(color='bgrcmyk')\n",
    "matplotlib.rcParams.update({\n",
    "    'figure.figsize': (8, 5)  # inches\n",
    "    ,\n",
    "    'font.size':\n",
    "    22  # points\n",
    "    ,\n",
    "    'legend.fontsize':\n",
    "    16  # points\n",
    "    ,\n",
    "    'lines.linewidth':\n",
    "    1.5  # points\n",
    "    ,\n",
    "    'axes.linewidth':\n",
    "    1.5  # points\n",
    "    ,\n",
    "    'text.usetex':\n",
    "    True  # Use LaTeX to layout text\n",
    "    ,\n",
    "    'font.family':\n",
    "    \"serif\"  # Use serifed fonts\n",
    "    ,\n",
    "    'xtick.major.size':\n",
    "    10  # length, points\n",
    "    ,\n",
    "    'xtick.major.width':\n",
    "    1.5  # points\n",
    "    ,\n",
    "    'xtick.minor.size':\n",
    "    6  # length, points\n",
    "    ,\n",
    "    'xtick.minor.width':\n",
    "    1  # points\n",
    "    ,\n",
    "    'ytick.major.size':\n",
    "    10  # length, points\n",
    "    ,\n",
    "    'ytick.major.width':\n",
    "    1.5  # points\n",
    "    ,\n",
    "    'ytick.minor.size':\n",
    "    6  # length, points\n",
    "    ,\n",
    "    \"xtick.minor.visible\":\n",
    "    True,\n",
    "    \"ytick.minor.visible\":\n",
    "    True,\n",
    "    'font.weight':\n",
    "    'bold',\n",
    "    'ytick.minor.width':\n",
    "    1  # points\n",
    "    ,\n",
    "    'font.serif': (\"Times\", \"Palatino\", \"Computer Modern Roman\",\n",
    "                   \"New Century Schoolbook\", \"Bookman\"),\n",
    "    'font.sans-serif':\n",
    "    (\"Helvetica\", \"Avant Garde\", \"Computer Modern Sans serif\"),\n",
    "    'font.monospace': (\"Courier\", \"Computer Modern Typewriter\"),\n",
    "    'font.cursive':\n",
    "    \"Zapf Chancery\"\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           377G         13G        358G        970M        5.3G        357G\n",
      "Swap:          1.0G          0B        1.0G\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# ML\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "#Set the display format to be scientific for ease of analysis\n",
    "# pd.options.display.float_format = '{:,.2g}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.14.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "import gensim \n",
    "from gensim import models\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora\n",
    "# import tensorflow \n",
    "\n",
    "import re, string \n",
    "import pandas as pd   \n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# libraries for visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No repo found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import subprocess\n",
    "    gitd = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))\n",
    "    githash = subprocess.check_output('git --git-dir={0:s} --work-tree={1:s} '\\\n",
    "              'rev-parse HEAD'.format(gitd+'/.git',gitd),shell=True).rstrip()\n",
    "except:\n",
    "    githash = 'No repo found'\n",
    "\n",
    "print(githash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==2.8.0 --user\n",
    "# !pip install torch==1.4.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 09 2020 \n",
      "\n",
      "CPython 3.6.2\n",
      "IPython 6.1.0\n",
      "\n",
      "jupyerlab not installed\n",
      "numpy 1.18.1\n",
      "scipy 1.4.1\n",
      "sklearn 0.21.3\n",
      "pandas 0.24.2\n",
      "matplotlib 2.0.2\n",
      "nltk 3.5\n",
      "gensim 3.8.3\n",
      "tensorflow 1.14.0\n",
      "spacy 2.2.4\n",
      "\n",
      "compiler   : GCC 5.4.0\n",
      "system     : Linux\n",
      "release    : 3.10.0-1062.9.1.el7.x86_64\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 44\n",
      "interpreter: 64bit\n",
      "host name  : worker0012\n",
      "Git hash   : 9f467f89feb15ee1bd2007bc58ac03880df5a02f\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -h -n -g -m -p jupyerlab,numpy,scipy,sklearn,pandas,matplotlib,nltk,gensim,tensorflow,spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:transformers.file_utils:PyTorch version 1.4.0 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"\n",
    "The US has \"passed the peak\" on new coronavirus cases, President Donald Trump said and predicted that some states would reopen this month.\n",
    "The US has over 637,000 confirmed Covid-19 cases and over 30,826 deaths, the highest for any country in the world.\n",
    "At the daily White House coronavirus briefing on Wednesday, Trump said new guidelines to reopen the country would be announced on Thursday after he speaks to governors.\n",
    "\"We'll be the comeback kids, all of us,\" he said. \"We want to get our country back.\"\n",
    "The Trump administration has previously fixed May 1 as a possible date to reopen the world's largest economy, but the president said some states may be able to return to normalcy earlier than that.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "print (\"original text preprocessed: \\n\", preprocess_text)\n",
    "\n",
    "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "# summmarize \n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webapp import load_review_helper, NLP_cleaning, NLP_summarization, ldacomplaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yelp_files(region):\n",
    "    region = region.lower()\n",
    "    if region == 'ny':\n",
    "        review_files = glob.glob('scraped_data_nodupl_biz/' + '1????*csv')\n",
    "    elif region == 'sf':\n",
    "        review_files = glob.glob('scraped_data_nodupl_biz/' + '9????*csv')\n",
    "    df_new = load_review_helper.read_all_reviews_in_area(review_files)\n",
    "    df_new.drop_duplicates(inplace=True, keep='first')\n",
    "    return df_new\n",
    "\n",
    "df_NY = load_yelp_files('ny')\n",
    "df_SF = load_yelp_files('sf')\n",
    "df = pd.concat([df_NY, df_SF])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_name</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>biz_url</th>\n",
       "      <th>biz_rating</th>\n",
       "      <th>biz_name</th>\n",
       "      <th>review_text_lem_cleaned</th>\n",
       "      <th>review_text_lem_cleaned_tokenized</th>\n",
       "      <th>review_text_lem_cleaned_tokenized_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lauren D.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>boyfriend live near walter consistently please...</td>\n",
       "      <td>/biz/walters-pet-styles-new-york?osq=pet+sitting</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Walter’s Pet Styles</td>\n",
       "      <td>staff month question service store today breat...</td>\n",
       "      <td>['staff', 'month', 'question', 'service', 'sto...</td>\n",
       "      <td>['staff', 'month', 'question', 'service', 'sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jackie W.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>dog jojo loves walters labradoodle puppy lots ...</td>\n",
       "      <td>/biz/walters-pet-styles-new-york?osq=pet+sitting</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Walter’s Pet Styles</td>\n",
       "      <td>lot energy work time place day mean lot exerci...</td>\n",
       "      <td>['lot', 'energy', 'work', 'time', 'place', 'da...</td>\n",
       "      <td>['lot', 'energy', 'time', 'day', 'lot', 'exerc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amelia H.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>love walter pup sage always crazy excited real...</td>\n",
       "      <td>/biz/walters-pet-styles-new-york?osq=pet+sitting</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Walter’s Pet Styles</td>\n",
       "      <td>day morning hand staff competent love lunchtim...</td>\n",
       "      <td>['day', 'morning', 'hand', 'staff', 'competent...</td>\n",
       "      <td>['day', 'morning', 'hand', 'staff', 'competent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paulina G.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>first visit definitely last super professional...</td>\n",
       "      <td>/biz/walters-pet-styles-new-york?osq=pet+sitting</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Walter’s Pet Styles</td>\n",
       "      <td>visit staff walter style fir aone place trust</td>\n",
       "      <td>['visit', 'staff', 'walter', 'style', 'fir', '...</td>\n",
       "      <td>['visit', 'staff', 'walter', 'style', 'fir', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kat N.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>walter amazing beginning corgi quinci loves ev...</td>\n",
       "      <td>/biz/walters-pet-styles-new-york?osq=pet+sitting</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Walter’s Pet Styles</td>\n",
       "      <td>minute day time pick day staff family</td>\n",
       "      <td>['minute', 'day', 'time', 'pick', 'day', 'staf...</td>\n",
       "      <td>['minute', 'day', 'time', 'pick', 'day', 'staf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_name  review_rating review_date  \\\n",
       "0   Lauren D.            5.0  2020-05-12   \n",
       "1   Jackie W.            5.0  2019-05-29   \n",
       "2   Amelia H.            5.0  2020-01-14   \n",
       "3  Paulina G.            5.0  2019-04-30   \n",
       "4      Kat N.            5.0  2020-03-19   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  boyfriend live near walter consistently please...   \n",
       "1  dog jojo loves walters labradoodle puppy lots ...   \n",
       "2  love walter pup sage always crazy excited real...   \n",
       "3  first visit definitely last super professional...   \n",
       "4  walter amazing beginning corgi quinci loves ev...   \n",
       "\n",
       "                                            biz_url  biz_rating  \\\n",
       "0  /biz/walters-pet-styles-new-york?osq=pet+sitting         4.5   \n",
       "1  /biz/walters-pet-styles-new-york?osq=pet+sitting         4.5   \n",
       "2  /biz/walters-pet-styles-new-york?osq=pet+sitting         4.5   \n",
       "3  /biz/walters-pet-styles-new-york?osq=pet+sitting         4.5   \n",
       "4  /biz/walters-pet-styles-new-york?osq=pet+sitting         4.5   \n",
       "\n",
       "              biz_name                            review_text_lem_cleaned  \\\n",
       "0  Walter’s Pet Styles  staff month question service store today breat...   \n",
       "1  Walter’s Pet Styles  lot energy work time place day mean lot exerci...   \n",
       "2  Walter’s Pet Styles  day morning hand staff competent love lunchtim...   \n",
       "3  Walter’s Pet Styles      visit staff walter style fir aone place trust   \n",
       "4  Walter’s Pet Styles              minute day time pick day staff family   \n",
       "\n",
       "                   review_text_lem_cleaned_tokenized  \\\n",
       "0  ['staff', 'month', 'question', 'service', 'sto...   \n",
       "1  ['lot', 'energy', 'work', 'time', 'place', 'da...   \n",
       "2  ['day', 'morning', 'hand', 'staff', 'competent...   \n",
       "3  ['visit', 'staff', 'walter', 'style', 'fir', '...   \n",
       "4  ['minute', 'day', 'time', 'pick', 'day', 'staf...   \n",
       "\n",
       "            review_text_lem_cleaned_tokenized_nostop  \n",
       "0  ['staff', 'month', 'question', 'service', 'sto...  \n",
       "1  ['lot', 'energy', 'time', 'day', 'lot', 'exerc...  \n",
       "2  ['day', 'morning', 'hand', 'staff', 'competent...  \n",
       "3  ['visit', 'staff', 'walter', 'style', 'fir', '...  \n",
       "4  ['minute', 'day', 'time', 'pick', 'day', 'staf...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del df_new\n",
    "df_new = pd.read_csv('data_model/cleaned_tokenized_df-2020-06-07.csv')\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_name</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>biz_url</th>\n",
       "      <th>biz_rating</th>\n",
       "      <th>biz_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lauren D.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>My boyfriend and I live near Walter's and have...</td>\n",
       "      <td>/biz/walters-pet-styles-new-york?osq=pet+sitting</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Walter’s Pet Styles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jackie W.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>Our dog Jojo LOVES walters! We have a labradoo...</td>\n",
       "      <td>/biz/walters-pet-styles-new-york?osq=pet+sitting</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Walter’s Pet Styles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amelia H.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>We love Walter's!! My pup Sage is always crazy...</td>\n",
       "      <td>/biz/walters-pet-styles-new-york?osq=pet+sitting</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Walter’s Pet Styles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paulina G.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>This is my first visit but it definitely won't...</td>\n",
       "      <td>/biz/walters-pet-styles-new-york?osq=pet+sitting</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Walter’s Pet Styles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kat N.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>Walter's has been amazing from the very beginn...</td>\n",
       "      <td>/biz/walters-pet-styles-new-york?osq=pet+sitting</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Walter’s Pet Styles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_name  review_rating review_date  \\\n",
       "0   Lauren D.            5.0  2020-05-12   \n",
       "1   Jackie W.            5.0  2019-05-29   \n",
       "2   Amelia H.            5.0  2020-01-14   \n",
       "3  Paulina G.            5.0  2019-04-30   \n",
       "4      Kat N.            5.0  2020-03-19   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  My boyfriend and I live near Walter's and have...   \n",
       "1  Our dog Jojo LOVES walters! We have a labradoo...   \n",
       "2  We love Walter's!! My pup Sage is always crazy...   \n",
       "3  This is my first visit but it definitely won't...   \n",
       "4  Walter's has been amazing from the very beginn...   \n",
       "\n",
       "                                            biz_url  biz_rating  \\\n",
       "0  /biz/walters-pet-styles-new-york?osq=pet+sitting         4.5   \n",
       "1  /biz/walters-pet-styles-new-york?osq=pet+sitting         4.5   \n",
       "2  /biz/walters-pet-styles-new-york?osq=pet+sitting         4.5   \n",
       "3  /biz/walters-pet-styles-new-york?osq=pet+sitting         4.5   \n",
       "4  /biz/walters-pet-styles-new-york?osq=pet+sitting         4.5   \n",
       "\n",
       "              biz_name  \n",
       "0  Walter’s Pet Styles  \n",
       "1  Walter’s Pet Styles  \n",
       "2  Walter’s Pet Styles  \n",
       "3  Walter’s Pet Styles  \n",
       "4  Walter’s Pet Styles  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bi-directional RNN in our encoding layer, and attention in our decoding layer\n",
    "similar to Xin Pan’s and Peter Liu’s model from “Sequence-to-Sequence with Attention Model for Text Summarization”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some cleaning unique to this:\n",
    "    \n",
    "- Convert to lowercase.\n",
    "- Replace contractions with their longer forms.\n",
    "- Remove any unwanted characters (this step needs to be done after replacing the contractions because apostrophes will be removed. Notice the backward slash before the hyphen. Without this slash, all characters that are ‘between’ the characters before and after the hyphen would be removed. This can create some unwanted effects. To give you an example, typing “a-d” would remove a,b,c,d.).\n",
    "- Stop words will only be removed from the descriptions. They are not very relevant in training the model, so by removing them we are able to train the model faster because there is less data. They will remain in the summaries because they are rather short and I would prefer for them to sound more like natural phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text,  \n",
    "                  flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the summaries and texts\n",
    "clean_summaries = []\n",
    "for summary in reviews.Summary:\n",
    "    clean_summaries.append(clean_text(summary, remove_stopwords=False))\n",
    "print(\"Summaries are complete.\")\n",
    "\n",
    "clean_texts = []\n",
    "for text in reviews.Text:\n",
    "    clean_texts.append(clean_text(text))\n",
    "print(\"Texts are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use pre-trained word vectors/embeddings\n",
    "\n",
    "ConceptNet Numberbatch (CN). Based on the work of its creators, it seems to outperform GloVe, which makes sense because CN is an ensemble of embeddings that includes GloVe.\n",
    "\n",
    "limit our vocabulary to words that are either in CN or occur more than 20 times in our dataset. This will allow us to have very good embeddings for every word because the model can better understand how words are related when they see them more times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-09 12:27:17--  https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-en-19.08.txt.gz\n",
      "Resolving conceptnet.s3.amazonaws.com (conceptnet.s3.amazonaws.com)... 52.216.184.35\n",
      "Connecting to conceptnet.s3.amazonaws.com (conceptnet.s3.amazonaws.com)|52.216.184.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 325403502 (310M) [application/x-gzip]\n",
      "Saving to: 'numberbatch-en-19.08.txt.gz'\n",
      "\n",
      "100%[======================================>] 325,403,502 65.6MB/s   in 4.9s   \n",
      "\n",
      "2020-06-09 12:27:22 (63.8 MB/s) - 'numberbatch-en-19.08.txt.gz' saved [325403502/325403502]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-en-19.08.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('CN_embeddings/numberbatch-en-19.08.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building your word_embedding_matrix , it is very important that you set its “dtype” of np.zeros to float32. The default value is float64, but this won’t work with TensorFlow because it expects values to be limited to _32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_to_int' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9f71615c8438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnb_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_to_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m word_embedding_matrix = np.zeros((nb_words, embedding_dim), \n\u001b[1;32m      4\u001b[0m                                  dtype=np.float32)\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab_to_int\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_to_int' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "nb_words = len(vocab_to_int)\n",
    "word_embedding_matrix = np.zeros((nb_words, embedding_dim), \n",
    "                                 dtype=np.float32)\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings_index:\n",
    "        word_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        # If word not in CN, create a random embedding for it\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        word_embedding_matrix[i] = new_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help train the model faster, we are going to sort the reviews by the length of the descriptions from shortest to longest. This will help each batch to have descriptions of similar lengths, which will result in less padding, thus less computing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (python3/3.6.2)",
   "language": "python",
   "name": "module-python3-3.6.2-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
